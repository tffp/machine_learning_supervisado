{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Práctica voluntaria\n",
    "\n",
    "Cálculo de un índice TF-IDF para palabras de un texto\n",
    "\n",
    "Tf-idf (Term frequency – Inverse document frequency)\n",
    "\n",
    "En el fichero indiceTF-IDF.py he elaborado tres funciones que corresponden a los cálculos de estas tres fórmulas matemáticas guiandome por la información que obtuve en https://towardsdatascience.com/natural-language-processing-feature-engineering-using-tf-idf-e8b9d00e7e76. En el mismo fichero .py comento cada función con su significado.\n",
    "\n",
    "\n",
    "$tf(t,d) = \\frac{f(t,d)}{max\\{f(t,d): t \\epsilon d\\}}$\n",
    "\n",
    "$idf(t,D) = log \\frac{|D|}{|\\{d \\epsilon D: t \\epsilon d\\}|} $\n",
    "\n",
    "$tfidf(t,d,D)  = tf(t,d)· idf(t,D)$\n",
    "\n",
    "Siendo: \n",
    "- $f(t,d)$ : la frecuencia bruta de t en un documento d de la colección D\n",
    "- $|D|$ : número de elementos de la colección\n",
    "- $|\\{d \\epsilon D: t \\epsilon d \\}|$ : número de documentos donde aparece t\n",
    "\n",
    "También intenté elaborar una función genérica al completo para que se pudiera adaptar a cualquier input de textos, pero se me complicó un poco por las diferentes características que pudieran tener cada uno de estos textos. \n",
    "\n",
    "A continuación aplico las funciones al caso que se pide de los documentos .txt del campus.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejecutamos el fichero .py en nuestra misma carpeta\n",
    "%run -i indiceTF-IDF.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['casa casa perro gato nevera',\n",
       " 'perro gato ordenador libro',\n",
       " 'libro espada cuento ordenador']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nuestra lista de documentos de texto\n",
    "files = [doc_reader(\"file01.txt\"),doc_reader(\"file02.txt\"),doc_reader(\"file03.txt\")]\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con este código vemos que es posible convertir nuestros elementos de 'files' en listas de palabras. Lo malo de esta estrategia es que se pierde toda información sobre la estructura del texto o frase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(files)\n",
    "bagOfWords1 = files[0].split(' ')\n",
    "bagOfWords2 = files[1].split(' ')\n",
    "bagOfWords3 = files[2].split(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar escribo el proceso de obtener el índice Tf-idf sin hacer el correspondiente preprocessing con las palabras porque no estoy segura de la universalidad de las funciones que he definido para ello y por tanto pongo aquí ambos ejemplos.\n",
    "\n",
    "Para analizar el indice Tf-idf de estas palabras, necesitaremos generar un diccionario que las contenga a todas, pero sin estar ninguna repetida. Así las juntamos todas las que salen al menos una vez en uno de los ficheros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'casa', 'cuento', 'espada', 'gato', 'libro', 'nevera', 'ordenador', 'perro'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniqueWords = set(bagOfWords1).union(set(bagOfWords2)).union(set(bagOfWords3))\n",
    "uniqueWords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora necesitamos codificar cada uno de nuestros ficheros dentro de este diccionario de palabras con las que contiene cada uno y su frecuencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "numOfWords1 = dict.fromkeys(uniqueWords,0)\n",
    "for word in bagOfWords1:\n",
    "    numOfWords1[word] += 1\n",
    "\n",
    "numOfWords2 = dict.fromkeys(uniqueWords,0)\n",
    "for word in bagOfWords2:\n",
    "    numOfWords2[word] += 1\n",
    "\n",
    "numOfWords3 = dict.fromkeys(uniqueWords,0)\n",
    "for word in bagOfWords3:\n",
    "    numOfWords3[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejecutamos la primera función auxiliar como vimos en la introducción\n",
    "tf1 = computeTF(numOfWords1, bagOfWords1)\n",
    "tf2 = computeTF(numOfWords2, bagOfWords2)\n",
    "tf3 = computeTF(numOfWords3, bagOfWords3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejecutamos la segunda función auxiliar como vimos en la introducción\n",
    "idfs= computeIDF([numOfWords1,numOfWords2,numOfWords3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nevera</th>\n",
       "      <th>libro</th>\n",
       "      <th>casa</th>\n",
       "      <th>ordenador</th>\n",
       "      <th>espada</th>\n",
       "      <th>perro</th>\n",
       "      <th>gato</th>\n",
       "      <th>cuento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.219722</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.439445</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.081093</td>\n",
       "      <td>0.081093</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.101366</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.101366</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.101366</td>\n",
       "      <td>0.101366</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.101366</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.101366</td>\n",
       "      <td>0.274653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.274653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     nevera     libro      casa  ordenador    espada     perro      gato  \\\n",
       "0  0.219722  0.000000  0.439445   0.000000  0.000000  0.081093  0.081093   \n",
       "1  0.000000  0.101366  0.000000   0.101366  0.000000  0.101366  0.101366   \n",
       "2  0.000000  0.101366  0.000000   0.101366  0.274653  0.000000  0.000000   \n",
       "\n",
       "     cuento  \n",
       "0  0.000000  \n",
       "1  0.000000  \n",
       "2  0.274653  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ejecutamos la tercera función que es la que ya nos proporciona el índice final.\n",
    "tfidf1 = computeTFIDF(tf1,idfs)\n",
    "tfidf2 = computeTFIDF(tf2,idfs)\n",
    "tfidf3 = computeTFIDF(tf3,idfs)\n",
    "\n",
    "df = pd.DataFrame([tfidf1,tfidf2,tfidf3]) \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando usando esta el *kit de herramientas de lenguaje natural de python* vemos que hay manera de identidicar las 'palabras inútiles' también llamadas **stopwords** de cada idioma.\n",
    "\n",
    "El módulo de python que calcula este índice directamente y de manera mas eficiente que veremos al final seguramente evalua mejor el peso que se le debe dar a estas palabras, que no nos aportan información distintiva sobre un texto.\n",
    "\n",
    "Tendría sentido hacer un preprocessing en el que tuvieramos funciones auxiliares como las definidas a continuación, teniendo en cuenta el tema de las **stopwords** y otros  como convertirlas todas a minúsculas, eliminar signos, palabras de una letra que no aportan información y convertir cada palabra a su raíz para poder estudiar la frecuencia de una manera mas amplia.\n",
    "\n",
    "\n",
    "He tenido algunos problemas universalizando estas funciones para cualquier fichero.txt dado, pero siguen la idea que deberían. Para que sea mas cómodo incluyo estas funciones que son auxiliares también en mi fichero .py.\n",
    "\n",
    "Para elaborar estas funciones auxiliares me he apoyado en la información hallada en: \n",
    "https://towardsdatascience.com/tf-idf-for-document-ranking-from-scratch-in-python-on-real-world-dataset-796d339a4089\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ges_bag1 = preprocess(bagOfWords1)\n",
    "ges_bag2 = preprocess(bagOfWords2)\n",
    "ges_bag3 = preprocess(bagOfWords3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cas', 'cuent', 'espad', 'gat', 'libr', 'never', 'orden', 'perr'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniqueWords_prueba = set(ges_bag1).union(set(ges_bag2)).union(set(ges_bag3))\n",
    "uniqueWords_prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "numOfWords1_p = dict.fromkeys(uniqueWords_prueba,0)\n",
    "for word in ges_bag1:\n",
    "    numOfWords1_p[word] += 1\n",
    "\n",
    "numOfWords2_p = dict.fromkeys(uniqueWords_prueba,0)\n",
    "for word in ges_bag2:\n",
    "    numOfWords2_p[word] += 1\n",
    "\n",
    "numOfWords3_p = dict.fromkeys(uniqueWords_prueba,0)\n",
    "for word in ges_bag3:\n",
    "    numOfWords3_p[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejecutamos la primera función auxiliar como vimos en la introducción\n",
    "tf1_p = computeTF(numOfWords1_p, ges_bag1)\n",
    "tf2_p = computeTF(numOfWords2_p, ges_bag2)\n",
    "tf3_p = computeTF(numOfWords3_p, ges_bag3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejecutamos la segunda función auxiliar como vimos en la introducción\n",
    "idfs_p= computeIDF([numOfWords1_p,numOfWords2_p,numOfWords3_p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cuent</th>\n",
       "      <th>libr</th>\n",
       "      <th>never</th>\n",
       "      <th>perr</th>\n",
       "      <th>gat</th>\n",
       "      <th>espad</th>\n",
       "      <th>orden</th>\n",
       "      <th>cas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.219722</td>\n",
       "      <td>0.081093</td>\n",
       "      <td>0.081093</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.439445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.101366</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.101366</td>\n",
       "      <td>0.101366</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.101366</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.274653</td>\n",
       "      <td>0.101366</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.274653</td>\n",
       "      <td>0.101366</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cuent      libr     never      perr       gat     espad     orden  \\\n",
       "0  0.000000  0.000000  0.219722  0.081093  0.081093  0.000000  0.000000   \n",
       "1  0.000000  0.101366  0.000000  0.101366  0.101366  0.000000  0.101366   \n",
       "2  0.274653  0.101366  0.000000  0.000000  0.000000  0.274653  0.101366   \n",
       "\n",
       "        cas  \n",
       "0  0.439445  \n",
       "1  0.000000  \n",
       "2  0.000000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ejecutamos la tercera función que es la que ya nos proporciona el índice final.\n",
    "tfidf1_p = computeTFIDF(tf1_p,idfs_p)\n",
    "tfidf2_p = computeTFIDF(tf2_p,idfs_p)\n",
    "tfidf3_p = computeTFIDF(tf3_p,idfs_p)\n",
    "\n",
    "df_p = pd.DataFrame([tfidf1_p,tfidf2_p,tfidf3_p]) \n",
    "df_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que en este caso, por las características del ejemplo de textos, no hay diferencia entre los índices obtenidos anteriormente y los que hemos conseguido al realizar el preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La manera ya incorporada a python de calcular este índice, obtiene valores bastante distintos a mis funciones porque usa versión más _fina_ de este índice en la que además se tiene mucho más en cuenta dar poco peso a las _stopwords_ como dijimos antes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>casa</th>\n",
       "      <th>cuento</th>\n",
       "      <th>espada</th>\n",
       "      <th>gato</th>\n",
       "      <th>libro</th>\n",
       "      <th>nevera</th>\n",
       "      <th>ordenador</th>\n",
       "      <th>perro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.806032</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.306504</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.403016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.306504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.562829</td>\n",
       "      <td>0.562829</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.428046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.428046</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       casa    cuento    espada      gato     libro    nevera  ordenador  \\\n",
       "0  0.806032  0.000000  0.000000  0.306504  0.000000  0.403016   0.000000   \n",
       "1  0.000000  0.000000  0.000000  0.500000  0.500000  0.000000   0.500000   \n",
       "2  0.000000  0.562829  0.562829  0.000000  0.428046  0.000000   0.428046   \n",
       "\n",
       "      perro  \n",
       "0  0.306504  \n",
       "1  0.500000  \n",
       "2  0.000000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(files)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "dense = vectors.todense()\n",
    "denselist = dense.tolist()\n",
    "df1= pd.DataFrame(denselist,columns = feature_names)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
